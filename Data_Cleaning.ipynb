{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "NFL_Data_Cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k0xs_F0f0Nl0",
        "k4kywKyd0QN_",
        "OWqKG1eG2l0B"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit (conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "f8bbe703e4409461e5c1796f0c401e26e62f32801f1a5b19455b89c31c613fbe"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\r\n",
        "## Simultaneous ECG and PCG recordings transformed into scrolling spectrogram (ECG) and log-mel spectrogram (PCG)\r\n",
        "\r\n",
        "There are two datasets which consist of Normal (EPHNOGram: https://physionet.org/content/ephnogram/1.0.0/) and Normal + Abnormal \\\\\r\n",
        "  (CINC/PhysioNet2016 Challenge: https://physionet.org/content/challenge-2016/1.0.0/#files) heart function sound recordings.\r\n",
        "  \r\n",
        "For the PhysioNet data: 'The normal recordings were\r\n",
        "from healthy subjects and the abnormal ones were from\r\n",
        "patients typically with heart valve defects and coronary\r\n",
        "artery disease (CAD). Heart valve defects include mitral\r\n",
        "valve prolapse, mitral regurgitation, aortic regurgitation,\r\n",
        "aortic stenosis and valvular surgery'\r\n",
        "\r\n",
        "For the EPHNOGram data: 'The current database, recorded by version 2.1 of the developed hardware, \r\n",
        "has been acquired from 24 healthy adults aged between 23 and 29 (average: 25.4 Â± 1.9 years) \r\n",
        "in 30min stress-test sessions during resting, walking, running and biking conditions, \r\n",
        "using indoor fitness center equipment. The dataset also contains several 30s sample records acquired during rest conditions.'\r\n",
        "\r\n",
        "The PhysioNet data is sampled at 2000Hz for both ECG and PCG, and the EPHNOGRAM data is sampled at 8000hz for both. \r\n",
        "The EPHNOGRAM data is resampled to 2000Hz for heterogenity."
      ],
      "metadata": {
        "id": "lrVW8SFt-clU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformations\r\n",
        "\r\n",
        "The LWTNet algorithm identifies object detection in video and audio using integrated attention over time. \r\n",
        "The ECG signals act as the 'video' after being transformed into spectrograms over windows of the signal \r\n",
        "(at 30 spectrogram windows/s, to mimic video frame rate), and the PCG audio recordings act as the audio to \r\n",
        "be synchronised and associated with labelled 'speakers' in the audio; heart sounds S1, S2, systole (S3, murmurs).\r\n",
        "The PCG audio is transformed into a log-Mel spectrogram for training through the modified LWTNet; ECG-PCG-LWTNet."
      ],
      "metadata": {
        "id": "T9GESfqB1Zdr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import wfdb\r\n",
        "from wfdb import processing\r\n",
        "import tqdm\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from visualise_data import peaks_hr\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "from helpers import clip_len, sample_rate_ecg, sample_rate_pcg, inputpath_physionet, inputpath_ephnogram_target, inputpath_ephnogram_data, outputpath, useDrive, get_filtered_df, create_new_folder"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'wfdb'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15668/471309745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwfdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwfdb\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mvisualise_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpeaks_hr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wfdb'"
          ]
        }
      ],
      "metadata": {
        "id": "PTQmcNrQxzMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4080785-9a87-4f13-ad99-24ed86885f0e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "\"\"\"# Cleaning PhysioNet 2016 Challenge Data\"\"\"\r\n",
        "def clean_physionet_data(inputpath_training, outputpath_, sample_clip_len=clip_len, ecg_sample_rate=sample_rate_ecg, pcg_sample_rate=sample_rate_pcg, create_spectrograms_ecg=True, create_spectrogram_pcg=True):\r\n",
        "  print(\"* Cleaning PhysioNet Data - Creating References [1/4] *\")\r\n",
        "  if os.path.exists(outputpath_+'physionet') and len(os.listdir(outputpath_+'physionet')) != 0:\r\n",
        "        print(\"! Warning: folder 'physionet' already exists - assuming PhysioNet data is clean !\")\r\n",
        "        return\r\n",
        "  else:\r\n",
        "    create_new_folder(outputpath_+'physionet')\r\n",
        "  if not os.path.isfile(inputpath_training+'REFERENCE.csv'):\r\n",
        "      raise ValueError(\"Error: file 'REFERENCE.csv' does not exist - aborting\")\r\n",
        "  ref_csv = pd.read_csv(inputpath_training+'REFERENCE.csv', names=['filename', 'label'])\r\n",
        "  data = pd.DataFrame(columns=['label', 'qrs_inds'])\r\n",
        "  \r\n",
        "  for index, ref in tqdm.tqdm(ref_csv.iterrows()):\r\n",
        "    # 1: Abnormal, -1: Normal\r\n",
        "    label = ref['label']\r\n",
        "    filename = ref['filename']\r\n",
        "    record = wfdb.rdrecord(inputpath_training+filename, channels=[0]) #sampfrom=0, sampto=10000\r\n",
        "    qrs_inds = processing.qrs.gqrs_detect(sig=record.p_signal[:,0], fs=record.fs)\r\n",
        "    print(f\"rr: {len(record.p_signal)}\")\r\n",
        "    # Plot results\r\n",
        "    peaks_hr(sig=record.p_signal, peak_inds=qrs_inds, fs=record.fs,\r\n",
        "         title=\"GQRS peak detection on record 100\")\r\n",
        "    row = pd.Series([label, qrs_inds])\r\n",
        "    data.append(row, ignore_index=True)\r\n",
        "  #receive_plays = get_filtered_df(csv, 'event', 'punt_received')\r\n",
        "  #play_nos = np.unique(receive_plays['playId'])\r\n",
        "  #for id in play_nos:\r\n",
        "  #    df = get_filtered_df(csv, 'playId', id)\r\n",
        "  #    games = np.unique(df['gameId'])\r\n",
        "  #    create_new_folder(outputpath_+foldername)\r\n",
        "  #players = pd.read_csv(inputpath_+\"players.csv\")\r\n",
        "  #players.columns = players.columns.str.replace(' ', '')\r\n",
        "  #players\r\n",
        "  #\"\"\"Converting all heights to inches\"\"\"\r\n",
        "  #if type(players['height']) is not String:\r\n",
        "  #  print(\"! Warning: 'height' attribute is not String - assuming 'players' is clean !\")\r\n",
        "  #  return players\r\n",
        "  #check = players['height'].str.split('-', expand=True)\r\n",
        "  #check.columns = ['feet', 'inches']\r\n",
        "  #check.loc[(check['inches'].notnull()), 'feet'] = check[check['inches'].notnull()]['feet'].astype(np.int16) * 12 + check[check['inches'].notnull()]['inches'].astype(np.int16)\r\n",
        "  #players['height'] = check['feet']\r\n",
        "  #players['height'] = players['height'].astype(np.float32)\r\n",
        "  #\"\"\"Making all dates the same format\"\"\"\r\n",
        "  ##TODO get birthdate from missing ones\r\n",
        " # for idx, row in players.iterrows():\r\n",
        "  #  if type(row['birthDate']) is String and \"/\" in row['birthDate']: \r\n",
        "  #        split = row[\"birthDate\"].split(\"/\")\r\n",
        "  #        players.loc[idx,\"birthDate\"] = split[2].replace(\" \",\"\")+\"-\"+split[0]+\"-\"+split[1]\r\n",
        "  #players.to_csv(outputpath_+\"players.csv\",index=False)\r\n",
        "  #cleaned_players = pd.read_csv(outputpath_+\"players.csv\")\r\n",
        "  #return cleaned_players\r\n",
        "\r\n",
        "print(\"*** Cleaning Data [0/4] ***\")\r\n",
        "print(\"** Cleaning PhysioNet Data **\")\r\n",
        "\r\n",
        "# Plot results\r\n",
        "#peaks_hr(sig=record.p_signal, peak_inds=qrs_inds, fs=record.fs,\r\n",
        "#         title=\"GQRS peak detection on record 100\")\r\n",
        "    \r\n",
        "# Correct the peaks shifting them to local maxima\r\n",
        "#min_bpm = 20\r\n",
        "#max_bpm = 230\r\n",
        "#min_gap = record.fs * 60 / min_bpm\r\n",
        "# Use the maximum possible bpm as the search radius\r\n",
        "#search_radius = int(record.fs * 60 / max_bpm)\r\n",
        "#corrected_peak_inds = processing.peaks.correct_peaks(record.p_signal[:,0], \r\n",
        "#                                                     peak_inds=qrs_inds,\r\n",
        "#                                                     search_radius=search_radius, \r\n",
        "#                                                     smooth_window_size=150)\r\n",
        "\r\n",
        "# Display results\r\n",
        "#print('Corrected GQRS detected peak indices:', sorted(corrected_peak_inds))\r\n",
        "#peaks_hr(sig=record.p_signal, peak_inds=sorted(corrected_peak_inds), fs=record.fs,\r\n",
        "#         title=\"Corrected GQRS peak detection on sampledata/100\")\r\n",
        "clean_physionet_data(inputpath_physionet, outputpath)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'clip_len' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15668/4054570827.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"# Cleaning PhysioNet 2016 Challenge Data\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mclean_physionet_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputpath_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_clip_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclip_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mecg_sample_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_rate_ecg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpcg_sample_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_rate_pcg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_spectrograms_ecg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_spectrogram_pcg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"* Cleaning PhysioNet Data - Creating References [1/4] *\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputpath_\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'physionet'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputpath_\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'physionet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"! Warning: folder 'physionet' already exists - assuming PhysioNet data is clean !\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'clip_len' is not defined"
          ]
        }
      ],
      "metadata": {
        "id": "DwKSLve11kwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting all heights to inches"
      ],
      "metadata": {
        "id": "1FqMk6B14_hs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "check = players['height'].str.split('-', expand=True)\r\n",
        "check.columns = ['feet', 'inches']\r\n",
        "check.loc[(check['inches'].notnull()), 'feet'] = check[check['inches'].notnull()]['feet'].astype(np.int16) * 12 + check[check['inches'].notnull()]['inches'].astype(np.int16)\r\n",
        "players['height'] = check['feet']\r\n",
        "players['height'] = players['height'].astype(np.float32)\r\n",
        "players"
      ],
      "outputs": [],
      "metadata": {
        "id": "Uu9CKKGB2A35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making all dates the same format"
      ],
      "metadata": {
        "id": "qrgz1URpLW0f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for idx, row in players.iterrows():\r\n",
        "  if \"/\" in row['birthDate']: \r\n",
        "        split = row[\"birthDate\"].split(\"/\")\r\n",
        "        players.loc[idx,\"birthDate\"] = split[2].replace(\" \",\"\")+\"-\"+split[0]+\"-\"+split[1]\r\n",
        "players"
      ],
      "outputs": [],
      "metadata": {
        "id": "l-NDVnuuHHjC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "players.to_csv(outputpath+\"cleaned_players.csv\", index=False)\r\n",
        "cleaned_players = pd.read_csv(outputpath+\"cleaned_players.csv\")\r\n",
        "cleaned_players"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZajNGrLcIu0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plays"
      ],
      "metadata": {
        "id": "PHVVzyBN0JPN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plays = pd.read_csv(\"plays.csv\")\r\n",
        "plays.head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "5oo17x-eUm0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are four special plays detailed. They should be given their own csvs."
      ],
      "metadata": {
        "id": "ESVYioYb-haU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plays['specialTeamsPlayType'].unique()"
      ],
      "outputs": [],
      "metadata": {
        "id": "zgOLYRIeY5dO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plays[plays['specialTeamsPlayType'] == \"Kickoff\"][\"specialTeamsResult\"].unique()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Fw74c1LkZb1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Touchback - Kickoff resulted in ball becoming dead in defending team's endzone, so defending team gain possesion at 25 or 20 yard line. Either has to land there and stop, or a player catches and kneels to end play.\n",
        "- Return - Kickoff resulted in ball being received by defending team and them running the ball up the field. (Is caught or becomes dead not in end zone?)\n",
        "- Muffed - Receiving team don't gain possession of the ball properly, and can only start at where the ball was downed?\n",
        "- Kickoff Team Recovery - kickoff team gain possesion of the ball after it crosses the receiving team's restraining line (35 yards) or a member of the receiving team possess the ball first.\n",
        "- Out of Bounds - out of bounds\n",
        "- Fair Catch - Receiver signals that they want a fair catch, meaning they can catch the ball without interference. Then the ball becomes dead at that spot and the receiving team cannot advance it.\n",
        "- Downed - Ball brought to the ground??"
      ],
      "metadata": {
        "id": "8Bgz9hUtjPND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plays[plays['specialTeamsPlayType'] == \"Punt\"][\"specialTeamsResult\"].unique()"
      ],
      "outputs": [],
      "metadata": {
        "id": "OH_NIQ-panWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Non-Special Teams Result - Punt is passed instead."
      ],
      "metadata": {
        "id": "jEYON5yz2pvR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plays[plays['specialTeamsPlayType'] == \"Field Goal\"][\"specialTeamsResult\"].unique()"
      ],
      "outputs": [],
      "metadata": {
        "id": "5LQwnom0aqNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Kick Attempt Good - goal scored\n",
        "- Kick Attempt No Good - goal missed\n",
        "- Blocked Kick Attempt - kick blocked by an opponent\n",
        "- Non-Special Teams Result - kick set up but passed instead?"
      ],
      "metadata": {
        "id": "uRAhmLEi4e2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plays[plays['specialTeamsPlayType'] == \"Extra Point\"][\"specialTeamsResult\"].unique()"
      ],
      "outputs": [],
      "metadata": {
        "id": "XvHZRkggauc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Non-Special Teams Result - Can choose to attempt another touchdown after first touchdown instead of conversion kick, so no one attempts the kick, kickerId is null. Mostly fails however."
      ],
      "metadata": {
        "id": "l6L5w2Jq6v_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kickoff"
      ],
      "metadata": {
        "id": "k0xs_F0f0Nl0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "kickoff = plays[plays['specialTeamsPlayType'] == \"Kickoff\"]\r\n",
        "kickoff.columns"
      ],
      "outputs": [],
      "metadata": {
        "id": "SdjwSFXleGMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The percentage of NA values in each column:"
      ],
      "metadata": {
        "id": "i7AhkClFfrgk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for column in kickoff.columns:\r\n",
        "  print(column,(kickoff[column].isnull().sum()/len(kickoff[column])*100))"
      ],
      "outputs": [],
      "metadata": {
        "id": "tUGtYt8BednF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Penalties have high percentages because they are rare, but still valid data\n",
        "- Kickoffs have no kick blocker so kickBlockerId is irrelevant here\n",
        "- passResult: Scrimmage outcome of the play if specialTeamsPlayResult is \"Non-Special Teams Result\", so irrelevant here\n",
        "- looks like yardlineNumber should all be 35 because that's where a kickoff occurs, but some maybe different because of pentalies?"
      ],
      "metadata": {
        "id": "O9M_HwW-fvPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "kickoff = kickoff.drop(columns=[\"kickBlockerId\",\"passResult\",\"specialTeamsPlayType\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "GN_V1Wp6gTtJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "kickoff.to_csv(outputpath+\"kickoff.csv\",index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "N0rRr6H9haqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "specialTeamsPlayType is removed because the csv only has data about one special type, so would be a column with all the same values"
      ],
      "metadata": {
        "id": "klFeqkjL-Pzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Punt"
      ],
      "metadata": {
        "id": "k4kywKyd0QN_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "punt = plays[plays['specialTeamsPlayType'] == \"Punt\"]\r\n",
        "punt"
      ],
      "outputs": [],
      "metadata": {
        "id": "X27XD9Pr0RUL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for column in punt.columns:\r\n",
        "  print(column,(punt[column].isnull().sum()/len(punt[column])*100))"
      ],
      "outputs": [],
      "metadata": {
        "id": "IexJ-F7R0ZKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Some kickerIds are null because the punt is not kicked (??), it is passed instead. Indicated by having the specialTeamsResult set to Non-Special Teams Result, and then the passResult shows the result of the pass.\n",
        "- kickBlockerId is mostly null because it is rare to block a punt. When not null, specialTeamsResult has Blocked Punt\n"
      ],
      "metadata": {
        "id": "uWV5EXV-1Bni"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "punt = punt.drop(columns=[\"specialTeamsPlayType\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "LmxLJjUB2OnZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "punt.to_csv(outputpath+\"punt.csv\",index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "l3JulZfL2TGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Field Goal"
      ],
      "metadata": {
        "id": "OWqKG1eG2l0B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fieldGoal = plays[plays['specialTeamsPlayType'] == \"Field Goal\"]\r\n",
        "fieldGoal"
      ],
      "outputs": [],
      "metadata": {
        "id": "9epbfRYV2zGm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for column in fieldGoal.columns:\r\n",
        "  print(column,(fieldGoal[column].isnull().sum()/len(fieldGoal[column])*100))"
      ],
      "outputs": [],
      "metadata": {
        "id": "3i9qFwJ929gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- kickReturnYardage is all null because the receiving cannot (??) advance the ball after a field goal ??\n",
        "- playResult is mostly 0 because most attempts score goals, so kicking team essentially gains no yards because play is reset. Will be negative if goal is missed so receiving team get the ball at their 8 yard mark (??). For blocked kicks, it's anyone's ball after so kicking team may or may not gain yards afterwards.\n",
        "- returnerId is mostly null because it's rare to return after a field goal??"
      ],
      "metadata": {
        "id": "CeUkf6125LKb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fieldGoal = fieldGoal.drop(columns=[\"specialTeamsPlayType\",\"kickReturnYardage\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "xM8GG-Ua6F9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fieldGoal.to_csv(outputpath+\"fieldGoal.csv\",index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "gFHrNSa66LkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Point"
      ],
      "metadata": {
        "id": "kYqm18hr6Ooz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "extraPoint = plays[plays['specialTeamsPlayType'] == \"Extra Point\"]\r\n",
        "extraPoint"
      ],
      "outputs": [],
      "metadata": {
        "id": "35hMcHlN6VcK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for column in extraPoint.columns:\r\n",
        "  print(column,(extraPoint[column].isnull().sum()/len(extraPoint[column])*100))"
      ],
      "outputs": [],
      "metadata": {
        "id": "PgSq0F4f7tLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- returnerId all null because no one returns\n",
        "- kickLength all null because kicks happen at same place\n",
        "- kickReturnYardage all null because you can't advance after an extra point attempt"
      ],
      "metadata": {
        "id": "yaOC_VRf82BW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "extraPoint = extraPoint.drop(columns=[\"specialTeamsPlayType\",\"kickReturnYardage\",\"returnerId\",\"kickLength\"])\r\n",
        "extraPoint.to_csv(outputpath+\"extraPoint.csv\",index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "n2J4HmHg9scD"
      }
    }
  ]
}
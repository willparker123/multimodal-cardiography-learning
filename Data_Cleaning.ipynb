{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lrVW8SFt-clU"
      },
      "source": [
        "# Data Cleaning\n",
        "## Simultaneous ECG and PCG recordings transformed into continuous wavelet transform (ECG) and log-mel spectrogram (PCG)\n",
        "\n",
        "There are two datasets which consist of Normal (EPHNOGram: https://physionet.org/content/ephnogram/1.0.0/) and Normal + Abnormal \\\\\n",
        "  (CINC/PhysioNet2016 Challenge: https://physionet.org/content/challenge-2016/1.0.0/#files) heart function sound recordings.\n",
        "  \n",
        "For the PhysioNet data: 'The normal recordings were\n",
        "from healthy subjects and the abnormal ones were from\n",
        "patients typically with heart valve defects and coronary\n",
        "artery disease (CAD). Heart valve defects include mitral\n",
        "valve prolapse, mitral regurgitation, aortic regurgitation,\n",
        "aortic stenosis and valvular surgery'\n",
        "\n",
        "For the EPHNOGram data: 'The current database, recorded by version 2.1 of the developed hardware, \n",
        "has been acquired from 24 healthy adults aged between 23 and 29 (average: 25.4 Â± 1.9 years) \n",
        "in 30min stress-test sessions during resting, walking, running and biking conditions, \n",
        "using indoor fitness center equipment. The dataset also contains several 30s sample records acquired during rest conditions.'\n",
        "\n",
        "The PhysioNet data is sampled at 2000Hz for both ECG and PCG, and the EPHNOGRAM data is sampled at 8000hz for both. \n",
        "The EPHNOGRAM data is resampled to 2000Hz for heterogenity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9GESfqB1Zdr"
      },
      "source": [
        "# Transformations\n",
        "\n",
        "The LWTNet algorithm identifies object detection in video and audio using integrated attention over time. \n",
        "The ECG signals act as the 'video' after being transformed into spectrograms over windows of the signal \n",
        "(at 30 spectrogram windows/s, to mimic video frame rate), and the PCG audio recordings act as the audio to \n",
        "be synchronised and associated with labelled 'speakers' in the audio; heart sounds S1, S2, systole (S3, murmurs).\n",
        "The PCG audio is transformed into a log-Mel spectrogram for training through the modified LWTNet; ECG-PCG-LWTNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTQmcNrQxzMv",
        "outputId": "e4080785-9a87-4f13-ad99-24ed86885f0e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'wfdb'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15668/471309745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwfdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwfdb\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mvisualise_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpeaks_hr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wfdb'"
          ]
        }
      ],
      "source": [
        "import wfdb\n",
        "from wfdb import processing\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from visualise_data import peaks_hr\n",
        "import os\n",
        "import pandas as pd\n",
        "from helpers import clip_len, sample_rate_ecg, sample_rate_pcg, inputpath_physionet, inputpath_ephnogram_target, inputpath_ephnogram_data, outputpath, useDrive, get_filtered_df, create_new_folder"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k0xs_F0f0Nl0",
        "k4kywKyd0QN_",
        "OWqKG1eG2l0B"
      ],
      "name": "NFL_Data_Cleaning.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f8bbe703e4409461e5c1796f0c401e26e62f32801f1a5b19455b89c31c613fbe"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit (conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
